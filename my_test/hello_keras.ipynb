{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "DeepCTR version 0.8.1 detected. Your version is 0.8.0.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.8.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from deepctr.models import DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat,get_feature_names\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['hist_item_id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-7f461d1d76c5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'hist_item_id'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'hist_cate_id'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36mdrop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   3695\u001B[0m                                            \u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3696\u001B[0m                                            \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minplace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3697\u001B[0;31m                                            errors=errors)\n\u001B[0m\u001B[1;32m   3698\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3699\u001B[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mdrop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   3109\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;32min\u001B[0m \u001B[0maxes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3110\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3111\u001B[0;31m                 \u001B[0mobj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_drop_axis\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3113\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m_drop_axis\u001B[0;34m(self, labels, axis, level, errors)\u001B[0m\n\u001B[1;32m   3141\u001B[0m                 \u001B[0mnew_axis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3142\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3143\u001B[0;31m                 \u001B[0mnew_axis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3144\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0maxis_name\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnew_axis\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mdrop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   4402\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0merrors\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m'ignore'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4403\u001B[0m                 raise KeyError(\n\u001B[0;32m-> 4404\u001B[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001B[0m\u001B[1;32m   4405\u001B[0m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m~\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4406\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelete\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['hist_item_id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "file_path=\"data/movielens_sample_din.txt\"\n",
    "feature_columns = [SparseFeat('user', 3, embedding_dim=10),\n",
    "                       SparseFeat('gender', 2, embedding_dim=4),\n",
    "                       SparseFeat('item_id', 3 + 1, embedding_dim=8),\n",
    "                       SparseFeat('cate_id', 2 + 1, embedding_dim=4),\n",
    "                       DenseFeat('pay_score', 1)]\n",
    "# feature_columns += [VarLenSparseFeat(SparseFeat('hist_item_id', vocabulary_size=3 + 1, embedding_dim=8, embedding_name='item_id'), maxlen=4),VarLenSparseFeat(SparseFeat('hist_cate_id', 2 + 1, embedding_dim=4, embedding_name='cate_id'), maxlen=4)]\n",
    "\n",
    "behavior_feature_list = [\"item_id\", \"cate_id\"]\n",
    "# label, user, gender, item_id, cate_id, hist_item_id, hist_cate_id, pay_score\n",
    "head = ['label', 'user', 'gender', 'item_id', 'cate_id', 'hist_item_id', 'hist_cate_id', 'pay_score']\n",
    "\n",
    "data = pd.read_csv(file_path, delimiter=',')\n",
    "y = data.pop('label')\n",
    "\n",
    "x = data\n",
    "x['hist_item_id'] = x['hist_item_id'].map(lambda x: x.split('|'))\n",
    "x['hist_cate_id'] = x['hist_cate_id'].map(lambda x: x.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user              int64\n",
       "gender            int64\n",
       "item_id           int64\n",
       "cate_id           int64\n",
       "hist_item_id     object\n",
       "hist_cate_id     object\n",
       "pay_score       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 2, 3, 0]\n",
       "1    [3, 2, 1, 0]\n",
       "2    [1, 2, 0, 0]\n",
       "Name: hist_item_id, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['hist_item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['hist_item_id'] = x['hist_item_id'].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user              int64\n",
       "gender            int64\n",
       "item_id           int64\n",
       "cate_id           int64\n",
       "hist_item_id     object\n",
       "hist_cate_id     object\n",
       "pay_score       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zealot/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zealot/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zealot/yizhou/git/DeepCTR/deepctr/layers/sequence.py:270: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zealot/yizhou/git/DeepCTR/deepctr/layers/sequence.py:270: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = DIN(feature_columns, behavior_feature_list)\n",
    "model.compile('adam', keras.losses.binary_crossentropy, metrics=[keras.metrics.AUC(), keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 7 array(s), but instead got the following list of 1 arrays: [array([[0, 0, 1, 1, array(['1', '2', '3', '0'], dtype='<U1'),\n        list(['1', '2', '2', '0']), 0.1],\n       [1, 1, 2, 2, array(['3', '2', '1', '0'], dtype='<U1'),\n        list(['2', '2', '1', '0']...",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-8287eec4213d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[1;32m    728\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    729\u001B[0m   def evaluate(self,\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001B[0m\n\u001B[1;32m    641\u001B[0m         \u001B[0msteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    642\u001B[0m         \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidation_split\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 643\u001B[0;31m         shuffle=shuffle)\n\u001B[0m\u001B[1;32m    644\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    645\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_standardize_user_data\u001B[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001B[0m\n\u001B[1;32m   2469\u001B[0m           \u001B[0mfeed_input_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2470\u001B[0m           \u001B[0mcheck_batch_axis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# Don't enforce the batch size.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2471\u001B[0;31m           exception_prefix='input')\n\u001B[0m\u001B[1;32m   2472\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2473\u001B[0m     \u001B[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001B[0m in \u001B[0;36mstandardize_input_data\u001B[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001B[0m\n\u001B[1;32m    527\u001B[0m                        \u001B[0;34m'Expected to see '\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnames\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m' array(s), '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    528\u001B[0m                        \u001B[0;34m'but instead got the following list of '\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 529\u001B[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001B[0m\u001B[1;32m    530\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnames\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    531\u001B[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001B[0;31mValueError\u001B[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 7 array(s), but instead got the following list of 1 arrays: [array([[0, 0, 1, 1, array(['1', '2', '3', '0'], dtype='<U1'),\n        list(['1', '2', '2', '0']), 0.1],\n       [1, 1, 2, 2, array(['3', '2', '1', '0'], dtype='<U1'),\n        list(['2', '2', '1', '0']..."
     ]
    }
   ],
   "source": [
    "model.fit(x, y, verbose=1, epochs=10, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_id</th>\n",
       "      <th>cate_id</th>\n",
       "      <th>hist_item_id</th>\n",
       "      <th>hist_cate_id</th>\n",
       "      <th>pay_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 0]</td>\n",
       "      <td>[1, 2, 2, 0]</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 2, 1, 0]</td>\n",
       "      <td>[2, 2, 1, 0]</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 0, 0]</td>\n",
       "      <td>[1, 2, 0, 0]</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  gender  item_id  cate_id  hist_item_id  hist_cate_id  pay_score\n",
       "0     0       0        1        1  [1, 2, 3, 0]  [1, 2, 2, 0]        0.1\n",
       "1     1       1        2        2  [3, 2, 1, 0]  [2, 2, 1, 0]        0.2\n",
       "2     2       0        3        2  [1, 2, 0, 0]  [1, 2, 0, 0]        0.3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-e20d23754fe4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_tensor_slices\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36mfrom_tensor_slices\u001B[0;34m(tensors)\u001B[0m\n\u001B[1;32m   1820\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mfunctools\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDatasetV2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_tensor_slices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1821\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mfrom_tensor_slices\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1822\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mDatasetV1Adapter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDatasetV2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_tensor_slices\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1823\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1824\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36mfrom_tensor_slices\u001B[0;34m(tensors)\u001B[0m\n\u001B[1;32m    442\u001B[0m       \u001B[0mDataset\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mA\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mDataset\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    443\u001B[0m     \"\"\"\n\u001B[0;32m--> 444\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mTensorSliceDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    445\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    446\u001B[0m   \u001B[0;32mclass\u001B[0m \u001B[0m_GeneratorState\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, element)\u001B[0m\n\u001B[1;32m   2370\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2371\u001B[0m     \u001B[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2372\u001B[0;31m     \u001B[0melement\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstructure\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormalize_element\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2373\u001B[0m     \u001B[0mbatched_spec\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstructure\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtype_spec_from_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2374\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tensors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstructure\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_batched_tensor_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatched_spec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py\u001B[0m in \u001B[0;36mnormalize_element\u001B[0;34m(element)\u001B[0m\n\u001B[1;32m    109\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m           normalized_components.append(\n\u001B[0;32m--> 111\u001B[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001B[0m\u001B[1;32m    112\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpack_sequence_as\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melement\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnormalized_components\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001B[0m\n\u001B[1;32m   1182\u001B[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001B[1;32m   1183\u001B[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001B[0;32m-> 1184\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconvert_to_tensor_v2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpreferred_dtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1185\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor_v2\u001B[0;34m(value, dtype, dtype_hint, name)\u001B[0m\n\u001B[1;32m   1240\u001B[0m       \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1241\u001B[0m       \u001B[0mpreferred_dtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype_hint\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1242\u001B[0;31m       as_ref=False)\n\u001B[0m\u001B[1;32m   1243\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1244\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001B[0m in \u001B[0;36minternal_convert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1295\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1296\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1297\u001B[0;31m       \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1298\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1299\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001B[0m in \u001B[0;36m_default_conversion_function\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_default_conversion_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m   \u001B[0;32mdel\u001B[0m \u001B[0mas_ref\u001B[0m  \u001B[0;31m# Unused.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconstant_op\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    225\u001B[0m   \"\"\"\n\u001B[1;32m    226\u001B[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0;32m--> 227\u001B[0;31m                         allow_broadcast=True)\n\u001B[0m\u001B[1;32m    228\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    263\u001B[0m       tensor_util.make_tensor_proto(\n\u001B[1;32m    264\u001B[0m           \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverify_shape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 265\u001B[0;31m           allow_broadcast=allow_broadcast))\n\u001B[0m\u001B[1;32m    266\u001B[0m   \u001B[0mdtype_value\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mattr_value_pb2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAttrValue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtensor_value\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m   const_tensor = g.create_op(\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001B[0m in \u001B[0;36mmake_tensor_proto\u001B[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    554\u001B[0m     raise TypeError(\n\u001B[1;32m    555\u001B[0m         \"Element type not supported in TensorProto: %s\" % numpy_dtype.name)\n\u001B[0;32m--> 556\u001B[0;31m   \u001B[0mappend_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor_proto\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproto_values\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    557\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    558\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mtensor_proto\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001B[0m in \u001B[0;36mtensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/yizhou/tool/miniconda3/envs/zealot_conda/lib/python3.7/site-packages/tensorflow_core/python/util/compat.py\u001B[0m in \u001B[0;36mas_bytes\u001B[0;34m(bytes_or_text, encoding)\u001B[0m\n\u001B[1;32m     69\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001B[0;32m---> 71\u001B[0;31m                     (bytes_or_text,))\n\u001B[0m\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Expected binary or unicode string, got 0"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x.values, y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x.drop(['hist_item_id',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.drop(['hist_item_id',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user              int64\n",
       "gender            int64\n",
       "item_id           int64\n",
       "cate_id           int64\n",
       "hist_item_id     object\n",
       "hist_cate_id     object\n",
       "pay_score       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(['hist_item_id',''])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}