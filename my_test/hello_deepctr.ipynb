{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat,get_feature_names\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('./criteo_sample.txt')\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I'+str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0,)\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26']\n"
     ]
    }
   ],
   "source": [
    "print(sparse_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13']\n"
     ]
    }
   ],
   "source": [
    "print(dense_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 40)\n",
      "   label    I1   I2     I3    I4       I5     I6    I7    I8     I9  ...  \\\n",
      "0      0   0.0    3  260.0   0.0  17668.0    0.0   0.0  33.0    0.0  ...   \n",
      "1      0   0.0   -1   19.0  35.0  30251.0  247.0   1.0  35.0  160.0  ...   \n",
      "2      0   0.0    0    2.0  12.0   2013.0  164.0   6.0  35.0  523.0  ...   \n",
      "3      0   0.0   13    1.0   4.0  16836.0  200.0   5.0   4.0   29.0  ...   \n",
      "4      0   0.0    0  104.0  27.0   1990.0  142.0   4.0  32.0   37.0  ...   \n",
      "5      0   0.0   -1   63.0  40.0   1470.0   61.0   4.0  37.0   46.0  ...   \n",
      "6      0   0.0  370    4.0   1.0   1787.0   65.0  14.0  25.0  489.0  ...   \n",
      "7      1  19.0   10   30.0  10.0      1.0    3.0  33.0  47.0  126.0  ...   \n",
      "8      0   0.0    0   36.0  22.0   4684.0  217.0   9.0  35.0  135.0  ...   \n",
      "9      0   2.0   11    8.0  23.0     30.0   11.0   2.0   8.0   23.0  ...   \n",
      "\n",
      "        C17       C18       C19       C20       C21 C22       C23       C24  \\\n",
      "0  e5ba7672  87c6f83c        -1        -1  0429f84b  -1  3a171ecb  c0d61a5c   \n",
      "1  d4bb7bd8  6fc84bfb        -1        -1  5155d8a3  -1  be7c41b4  ded4aac9   \n",
      "2  e5ba7672  675c9258        -1        -1  2e01979f  -1  bcdee96c  6d5d1302   \n",
      "3  e5ba7672  52e44668        -1        -1  e587c466  -1  32c7478e  3b183c5c   \n",
      "4  e5ba7672  25c88e42  21ddcdc9  b1252a9d  0e8585d2  -1  32c7478e  0d4a6d1a   \n",
      "5  e5ba7672  d3303ea5  21ddcdc9  b1252a9d  7633c7c8  -1  32c7478e  17f458f7   \n",
      "6  3486227d  642f2610  55dd3565  b1252a9d  5c8dc711  -1  423fab69  45ab94c8   \n",
      "7  e5ba7672  a78bd508  21ddcdc9  5840adea  c2a93b37  -1  32c7478e  1793a828   \n",
      "8  e5ba7672  7ce63c71        -1        -1  af5dc647  -1  dbb486d7  1793a828   \n",
      "9  07c540c4  c21c3e4c  21ddcdc9  a458ea53  31c8e642  -1  c7dc6720  3e983c86   \n",
      "\n",
      "        C25       C26  \n",
      "0        -1        -1  \n",
      "1        -1        -1  \n",
      "2        -1        -1  \n",
      "3        -1        -1  \n",
      "4  001f3601  92c878de  \n",
      "5  001f3601  71236095  \n",
      "6  2bf691b1  c84c4aec  \n",
      "7  e8b83407  2fede552  \n",
      "8        -1        -1  \n",
      "9  9b3e8820  d597922b  \n",
      "\n",
      "[10 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(data))\n",
    "print(data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Simple preprocessing\n",
    "**Label Encoding: map the features to integer value from 0 ~ len(#unique) - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hash Encoding: map the features to a fix range,like 0 ~ 9999.We have 2 methods to do that:**\n",
    "\n",
    "Do feature hashing before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HashEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9bb0f54c8968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msparse_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlbe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHashEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HashEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = HashEncoder()\n",
    "    data[feat] = lbe.transform(data[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do feature hashing on the fly in training process\n",
    "\n",
    "We can do feature hashing by setting use_hash=True in SparseFeat or VarlenSparseFeat in Step3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And for dense numerical features,they are usually discretized to buckets,here we use normalization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate feature columns\n",
    "\n",
    "For sparse features, we transform them into dense vectors by embedding techniques. For dense numerical features, we concatenate them to the input tensors of fully connected layer.\n",
    "\n",
    "And for varlen(multi-valued) sparse features,you can use VarlenSparseFeat. Visit examples of using VarlenSparseFeat\n",
    "\n",
    "**Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepctr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe6ec92069d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepctr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepctr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseFeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVarLenSparseFeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseFeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepctr'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from deepctr.models import DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat,get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
