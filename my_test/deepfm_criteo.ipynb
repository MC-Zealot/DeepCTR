{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classification: Criteo\n",
    "In this example,we simply normailize the dense feature between 0 and 1,you can try other transformation technique like log normalization or discretization.Then we use SparseFeat and DenseFeat to generate feature columns for sparse features and dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr.models import *\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse_features len: 26\n",
      "dense_features len: 13\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./criteo_sample.txt')\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1,27)]\n",
    "dense_features = ['I' + str(i) for i in range(1,14)]\n",
    "print(\"sparse_features len:\",len(sparse_features))\n",
    "print(\"dense_features len:\",len(dense_features))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label   I1  I2     I3    I4       I5     I6   I7    I8     I9  ...  \\\n",
      "0      0  0.0   3  260.0   NaN  17668.0    NaN  NaN  33.0    NaN  ...   \n",
      "1      0  NaN  -1   19.0  35.0  30251.0  247.0  1.0  35.0  160.0  ...   \n",
      "2      0  0.0   0    2.0  12.0   2013.0  164.0  6.0  35.0  523.0  ...   \n",
      "3      0  NaN  13    1.0   4.0  16836.0  200.0  5.0   4.0   29.0  ...   \n",
      "\n",
      "        C17       C18  C19  C20       C21  C22       C23       C24  C25  C26  \n",
      "0  e5ba7672  87c6f83c  NaN  NaN  0429f84b  NaN  3a171ecb  c0d61a5c  NaN  NaN  \n",
      "1  d4bb7bd8  6fc84bfb  NaN  NaN  5155d8a3  NaN  be7c41b4  ded4aac9  NaN  NaN  \n",
      "2  e5ba7672  675c9258  NaN  NaN  2e01979f  NaN  bcdee96c  6d5d1302  NaN  NaN  \n",
      "3  e5ba7672  52e44668  NaN  NaN  e587c466  NaN  32c7478e  3b183c5c  NaN  NaN  \n",
      "\n",
      "[4 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "data[sparse_features] = data[sparse_features].fillna('-1')\n",
    "data[dense_features] = data[dense_features].fillna(0)\n",
    "target = data['label']\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    I1  I2     I3    I4       I5     I6   I7    I8     I9  I10  I11  I12   I13\n",
      "0  0.0   3  260.0   0.0  17668.0    0.0  0.0  33.0    0.0  0.0  0.0  0.0   0.0\n",
      "1  0.0  -1   19.0  35.0  30251.0  247.0  1.0  35.0  160.0  0.0  1.0  0.0  35.0\n",
      "2  0.0   0    2.0  12.0   2013.0  164.0  6.0  35.0  523.0  0.0  3.0  0.0  18.0\n",
      "3  0.0  13    1.0   4.0  16836.0  200.0  5.0   4.0   29.0  0.0  2.0  0.0   4.0\n"
     ]
    }
   ],
   "source": [
    "# print(data[0:4])\n",
    "print(data[dense_features][0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Label Encoding for sparse features,and do simple Transformation for dense features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "mms = MinMaxScaler(feature_range(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.count #unique features for each sparse field,and record dense feature field name**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sparse_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fixlen_feature_columns=[]\n",
    "for i,feat in enumerate(sparse_features):\n",
    "    sf = SparseFeat(feat, vocabulary_size=len(data[feat].unique()),embedding_dim=4)\n",
    "    fixlen_feature_columns.append(sf)\n",
    "    print(i,feat,len(data[feat].unique()), sf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for feat in dense_features:\n",
    "    df = DenseFeat(feat, dimension=1)\n",
    "    fixlen_feature_columns.append(df)\n",
    "    print(feat,len(data[feat].unique()), df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(fixlen_feature_columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "# feature_names = get_feature_names(fixlen_feature_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3.generate input data for model**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. Define Model, train, predict and evaluate**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(\"adam\",\"binary_crossentropy\",metrics=['binary_crossentropy'],)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history=model.fit(train_model_input, train[target].values, batch_size=256, epochs=10, verbose=2,\n",
    "                 validation_split=0.2,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_ans=model.predict(test_model_input, batch_size=256)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26']\n"
     ]
    }
   ],
   "source": [
    "print(sparse_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C1 27 SparseFeat(name='C1', vocabulary_size=27, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a4110bb90>, embedding_name='C1', group_name='default_group', trainable=True)\n",
      "1 C2 92 SparseFeat(name='C2', vocabulary_size=92, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a4110bb10>, embedding_name='C2', group_name='default_group', trainable=True)\n",
      "2 C3 172 SparseFeat(name='C3', vocabulary_size=172, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a41101c10>, embedding_name='C3', group_name='default_group', trainable=True)\n",
      "3 C4 157 SparseFeat(name='C4', vocabulary_size=157, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a40fe5c50>, embedding_name='C4', group_name='default_group', trainable=True)\n",
      "4 C5 12 SparseFeat(name='C5', vocabulary_size=12, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452f1410>, embedding_name='C5', group_name='default_group', trainable=True)\n",
      "5 C6 7 SparseFeat(name='C6', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452a3b90>, embedding_name='C6', group_name='default_group', trainable=True)\n",
      "6 C7 183 SparseFeat(name='C7', vocabulary_size=183, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a4528e990>, embedding_name='C7', group_name='default_group', trainable=True)\n",
      "7 C8 19 SparseFeat(name='C8', vocabulary_size=19, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a45277850>, embedding_name='C8', group_name='default_group', trainable=True)\n",
      "8 C9 2 SparseFeat(name='C9', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a45267410>, embedding_name='C9', group_name='default_group', trainable=True)\n",
      "9 C10 142 SparseFeat(name='C10', vocabulary_size=142, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a45277810>, embedding_name='C10', group_name='default_group', trainable=True)\n",
      "10 C11 173 SparseFeat(name='C11', vocabulary_size=173, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a40e82810>, embedding_name='C11', group_name='default_group', trainable=True)\n",
      "11 C12 170 SparseFeat(name='C12', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452b3b10>, embedding_name='C12', group_name='default_group', trainable=True)\n",
      "12 C13 166 SparseFeat(name='C13', vocabulary_size=166, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452a3090>, embedding_name='C13', group_name='default_group', trainable=True)\n",
      "13 C14 14 SparseFeat(name='C14', vocabulary_size=14, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452a3a10>, embedding_name='C14', group_name='default_group', trainable=True)\n",
      "14 C15 170 SparseFeat(name='C15', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a45277750>, embedding_name='C15', group_name='default_group', trainable=True)\n",
      "15 C16 168 SparseFeat(name='C16', vocabulary_size=168, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a4528ec90>, embedding_name='C16', group_name='default_group', trainable=True)\n",
      "16 C17 9 SparseFeat(name='C17', vocabulary_size=9, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a4528e410>, embedding_name='C17', group_name='default_group', trainable=True)\n",
      "17 C18 127 SparseFeat(name='C18', vocabulary_size=127, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452676d0>, embedding_name='C18', group_name='default_group', trainable=True)\n",
      "18 C19 44 SparseFeat(name='C19', vocabulary_size=44, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452b36d0>, embedding_name='C19', group_name='default_group', trainable=True)\n",
      "19 C20 4 SparseFeat(name='C20', vocabulary_size=4, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452b3550>, embedding_name='C20', group_name='default_group', trainable=True)\n",
      "20 C21 169 SparseFeat(name='C21', vocabulary_size=169, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a4528e510>, embedding_name='C21', group_name='default_group', trainable=True)\n",
      "21 C22 6 SparseFeat(name='C22', vocabulary_size=6, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a4110bd10>, embedding_name='C22', group_name='default_group', trainable=True)\n",
      "22 C23 10 SparseFeat(name='C23', vocabulary_size=10, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452df5d0>, embedding_name='C23', group_name='default_group', trainable=True)\n",
      "23 C24 125 SparseFeat(name='C24', vocabulary_size=125, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a4110ba90>, embedding_name='C24', group_name='default_group', trainable=True)\n",
      "24 C25 20 SparseFeat(name='C25', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a459a9d10>, embedding_name='C25', group_name='default_group', trainable=True)\n",
      "25 C26 90 SparseFeat(name='C26', vocabulary_size=90, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x1a452a3c90>, embedding_name='C26', group_name='default_group', trainable=True)\n"
     ]
    }
   ],
   "source": [
    "fixlen_feature_columns=[]\n",
    "for i,feat in enumerate(sparse_features):\n",
    "    sf = SparseFeat(feat, vocabulary_size=len(data[feat].unique()),embedding_dim=4)\n",
    "    fixlen_feature_columns.append(sf)\n",
    "    print(i,feat,len(data[feat].unique()), sf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1 14 DenseFeat(name='I1', dimension=1, dtype='float32')\n",
      "I2 68 DenseFeat(name='I2', dimension=1, dtype='float32')\n",
      "I3 55 DenseFeat(name='I3', dimension=1, dtype='float32')\n",
      "I4 35 DenseFeat(name='I4', dimension=1, dtype='float32')\n",
      "I5 172 DenseFeat(name='I5', dimension=1, dtype='float32')\n",
      "I6 92 DenseFeat(name='I6', dimension=1, dtype='float32')\n",
      "I7 42 DenseFeat(name='I7', dimension=1, dtype='float32')\n",
      "I8 41 DenseFeat(name='I8', dimension=1, dtype='float32')\n",
      "I9 113 DenseFeat(name='I9', dimension=1, dtype='float32')\n",
      "I10 4 DenseFeat(name='I10', dimension=1, dtype='float32')\n",
      "I11 15 DenseFeat(name='I11', dimension=1, dtype='float32')\n",
      "I12 5 DenseFeat(name='I12', dimension=1, dtype='float32')\n",
      "I13 43 DenseFeat(name='I13', dimension=1, dtype='float32')\n"
     ]
    }
   ],
   "source": [
    "for feat in dense_features:\n",
    "    df = DenseFeat(feat, dimension=1)\n",
    "    fixlen_feature_columns.append(df)\n",
    "    print(feat,len(data[feat].unique()), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(fixlen_feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "# feature_names = get_feature_names(fixlen_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.generate input data for model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Define Model, train, predict and evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\",\"binary_crossentropy\",metrics=['binary_crossentropy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'dict'> containing {\"<class 'str'>\"} keys and {\"<class 'pandas.core.series.Series'>\"} values), <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taoyizhou/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/taoyizhou/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 32 samples\n",
      "Epoch 1/10\n",
      "128/128 - 6s - loss: 0.7033 - binary_crossentropy: 0.7033 - val_loss: 0.7107 - val_binary_crossentropy: 0.7107\n",
      "Epoch 2/10\n",
      "128/128 - 0s - loss: 0.6861 - binary_crossentropy: 0.6861 - val_loss: 0.6942 - val_binary_crossentropy: 0.6942\n",
      "Epoch 3/10\n",
      "128/128 - 0s - loss: 0.6695 - binary_crossentropy: 0.6695 - val_loss: 0.6778 - val_binary_crossentropy: 0.6778\n",
      "Epoch 4/10\n",
      "128/128 - 0s - loss: 0.6532 - binary_crossentropy: 0.6532 - val_loss: 0.6614 - val_binary_crossentropy: 0.6614\n",
      "Epoch 5/10\n",
      "128/128 - 0s - loss: 0.6373 - binary_crossentropy: 0.6373 - val_loss: 0.6451 - val_binary_crossentropy: 0.6451\n",
      "Epoch 6/10\n",
      "128/128 - 0s - loss: 0.6216 - binary_crossentropy: 0.6216 - val_loss: 0.6290 - val_binary_crossentropy: 0.6290\n",
      "Epoch 7/10\n",
      "128/128 - 0s - loss: 0.6061 - binary_crossentropy: 0.6061 - val_loss: 0.6130 - val_binary_crossentropy: 0.6130\n",
      "Epoch 8/10\n",
      "128/128 - 0s - loss: 0.5907 - binary_crossentropy: 0.5906 - val_loss: 0.5973 - val_binary_crossentropy: 0.5973\n",
      "Epoch 9/10\n",
      "128/128 - 0s - loss: 0.5753 - binary_crossentropy: 0.5753 - val_loss: 0.5818 - val_binary_crossentropy: 0.5817\n",
      "Epoch 10/10\n",
      "128/128 - 0s - loss: 0.5601 - binary_crossentropy: 0.5600 - val_loss: 0.5665 - val_binary_crossentropy: 0.5665\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_model_input, train[target].values, batch_size=256, epochs=10, verbose=2,\n",
    "                 validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'dict'> containing {\"<class 'str'>\"} keys and {\"<class 'pandas.core.series.Series'>\"} values), <class 'NoneType'>\n",
      "test LogLoss 0.5482\n",
      "test AUC 0.6061\n"
     ]
    }
   ],
   "source": [
    "pred_ans=model.predict(test_model_input, batch_size=256)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}